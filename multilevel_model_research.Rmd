---
title: "Multilevel Models - Applications to Human Factors Research"
author: "Courtney Goodridge"
date: "17/11/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This script contains the analysis for the manuscripts: *Multilevel Models: Applications and Uses in Human Factors Research*

Data for the first analysis is from the Mole et al (2020) manuscript. This manuscript reference is: Mole, C., Pekkanen, J., Sheppard, W., Louw, T., Romano, R., Merat, N., ... & Wilkie, R. (2020). Predicting takeover response to silent automated vehicle failures. Plos one, 15(11), e0242825. 

Data and analysis scripts can be found on OSF: https://osf.io/aw8kp/. 


First we load the necessary packages needed for this analysis

## Packages

```{r}
if(!require(here)) install.packages("here")
library(here)

if(!require(ggplot2)) install.packages("ggplot2")
library(ggplot2)

if(!require(dplyr)) install.packages("dplyr")
library(dplyr)

if(!require(tidyr)) install.packages("tidyr")
library(tidyr)

if(!require(viridis)) install.packages("viridis")
library(viridis)

if(!require(lme4)) install.packages("lme4")
library(lme4)

if(!require(data.table)) install.packages("data.table")
library(data.table)

if(!require(emmeans)) install.packages("emmeans")
library(emmeans)

if(!require(patchwork)) install.packages("patchwork")
library(patchwork)

if(!require(marginaleffects)) install.packages("marginaleffects")
library(marginaleffects)

if(!require(purrr)) install.packages("purrr")
library(purrr)
```

## Data

```{r}
steering_data <- fread(file = here::here("ITS/Multilevel models paper/Mole et al (2020) data and analysis/collated_steering.csv"))
```

## Calculating reaction time

Now the data has been loaded, the reaction time can be calculated. I calculate steering wheel angle and mirror the directional variables for completeness but this is not strictly necessary (only TLC_takeover will be used for the analysis). 

```{r}
# Mole et al (2020) calculating the SWA. I won't be using that for the analysis, but for completeness I calculate it here.
steering_data <- steering_data %>%
  dplyr::rename(swv = swa) %>%
  dplyr::mutate(swa = swv * 90)

# Next the data mirrored. Again, I am only focusing on timing variable so these won't be needed for the analysis but are included for completeness.
steering_data <- steering_data %>% 
  dplyr::mutate(world_x_mirrored = if_else(bend == -1, world_x * -1, world_x),
                swa_mirrored = if_else(bend == -1, swa * -1, swa),
                swv_mirrored = if_else(bend == -1, swv * -1, swv),
                sb_mirrored = if_else(bend == -1, steeringbias * -1, steeringbias))

# function for calculating the TLC from the offset where is varies 
TLC_from_offset <- function(b, w = 1.5, r = 80, v = 8){
  b = b / 180 * pi
  
  TLC = sqrt(w*(2*r + sign(b)*w)/(abs(b)*r*v))
}

steering_data <- steering_data %>% 
  dplyr::mutate(TLC_calc = TLC_from_offset(sab))


#add RT and disengage flag. This code calculates RT. I had to alter it slightly to include an if statement where if the auto_false was length 0 (i.e., a person never disengaged), it was set to NA instead of being empty. This allows the is.na() function to work in the following lines of code)
disengage_RT <- function(onsettime, timestamp_trial, autoflag){
  
  #pick first frame where autoflag == false, then take the timestamp and minus the onset_time
  auto_false <- which(autoflag == FALSE) # 1) select the autoflags which are false
  if(length(auto_false) == 0){ # 2) if there is no false autoflag, set auto_false to NA
    auto_false = NA
  }
  disengage_index <- first(auto_false) # 3 select the first frame that automation was disengaged
  disengage_trialtime <- timestamp_trial[disengage_index] # 4) select the trial time of the automation disengagement
  onset_time <- first(onsettime) # 5 Select the first onset time
  RT <- disengage_trialtime - onset_time # 6 subtract onset time from disengage trial time (can be negative)
  return(RT) # return the RT
  
}

# calculate RT
steering_data <- steering_data  %>% 
  dplyr::group_by(ppid, sab, cogload, trialn) %>% 
  dplyr::mutate(RT = disengage_RT(onsettime, timestamp_trial, autoflag),
         disengaged = ifelse(is.na(RT), 0, 1) # whether or not they actually took over.
  )

# change cogload variable into a factor
steering_data$cogload <- as.factor(steering_data$cogload)


#rename cogload factors so that it makes sense - no load and load
steering_data$cogload <- plyr::mapvalues(steering_data$cogload, from = c("None", "Middle"), to = c("noload", "load"))

#create unique trial id
steering_data <- steering_data %>% 
  dplyr::mutate(trialid = paste(ppid, cogload, trialn, sep = "_"))

# select reaction times for each condition
data_RTs <- steering_data %>% 
  dplyr::ungroup() %>% 
  dplyr::group_by(ppid, cogload, trialn) %>% 
  dplyr::summarise(RT = first(RT),
                   disengaged = first(disengaged), #whether or not they actually took over.
                   premature = ifelse(RT <= 0, 1, 0),
                   sab = first(sab),
                   maxsb = max(abs(sb_mirrored)),
                   onsettime = first(onsettime),
                   design = first(design),
                   #simTLC = first(simulated_TLC),
                   autofile_i = first(autofile_i),
                   TLC_calc = first(TLC_calc))
```

## Calculating TLC_takeover

To calculate the TLC_takeover, the simulated timings for the silent failures need to be merged with the reaction times. This is done in the following chunk. 

```{r}
# loading simualted_TLC
sim_TLCs <- fread(file = here::here("ITS/Multilevel models paper/Mole et al (2020) data and analysis/simulated_ttlcs.csv"))

# merge simulated TLCs with RT dataframe
data_RTs <- merge(data_RTs, sim_TLCs, by = c("sab","onsettime","autofile_i"))

# calculating TLC_takeover
data_RTs <- data_RTs %>% 
  dplyr::mutate(TLC_onset = simulated_ttlc,
                TLC_takeover = TLC_onset - RT,
                time_remaining = 15 - onsettime,
                early = time_remaining - RT,
                TLC_end_of_trial = TLC_onset - time_remaining)  

# filter out conditions where takeovers did not happen, or they happened too early (i.e., before the onset of the failure)
data_RTs_cens <- data_RTs %>%
  dplyr::filter(premature == 0 | is.na(premature)) %>% 
  dplyr::mutate(censored = ifelse(is.na(TLC_takeover), -1,
                                  ifelse(TLC_takeover < TLC_end_of_trial, -1, 0)))

data_RTs_cens$cogload <- relevel(data_RTs_cens$cogload, "noload")

#13 moves the wheel pretty much every trial before they should do so they are filtered out
data_RTs_cens <- dplyr::filter(data_RTs_cens, ppid != 13) 

# removing NAs (i.e, when people did not disengage) and only concentrating on no load conditions
data_RTs_cens_NA_removed <- data_RTs_cens %>%
  dplyr::filter(disengaged == 1, cogload == "noload")

# only focusing on balanced conditions and rounding the onset values
data_RTs_cens_NA_removed <- data_RTs_cens_NA_removed %>% 
  dplyr::filter(design == "balanced") %>% 
  dplyr::mutate(TLC_failure = round(TLC_onset, digits = 2)) 
```

## Distribution of TLC_takeover

The distribution of TLC_takeover reasonably follows a Gaussian shape, however there is some skew (positively skewed with an extended right tail). This suggests that a Gaussian distribution might not be the best to model TLC_takeover. However it should be noted that it is the residuals that should be normally distributed, rather than the response metric itself. We'll go forward with a Gaussian distribution and inspect the fit. 

```{r}
# Overall distribution of TLC_takeover
ggplot(data = data_RTs_cens_NA_removed, mapping = aes(x = TLC_takeover)) +
  geom_histogram(alpha = 0.5, bins = 50, col = "black") +
  ggtitle(expression("Overall distribution of" ~ TLC[t]))

# Distribution of TLC_takeover within each failure severity condition
ggplot(data = data_RTs_cens_NA_removed, mapping = aes(x = TLC_takeover)) +
  geom_histogram(aes(fill = as.factor(TLC_failure)), alpha=0.5, bins=50, col = "black") +
  facet_wrap(~ TLC_failure) +
  ggtitle("Distribution within each failure condition")
```

## Fitting an ordinary linear regression

```{r}
# fitting a linear regression model
mod_1<- lm(TLC_takeover ~ TLC_failure, data = data_RTs_cens_NA_removed)

# summarizing the linear regression model to see the parameter estimates
summary(mod_1)

# confidence intervals for the linear regression
confint(mod_1)
```

## Investigating the residual errors

Here we plot the fitted values against the residuals. 

```{r}
mod_1_fortified <- fortify(mod_1)

ggplot(mod_1_fortified, aes(x = .fitted, y = .resid)) + 
  geom_point() +
  geom_hline(yintercept = 0) +
  theme_bw() +
  theme(legend.position = c(.9, .7), axis.title.x = element_text(size = 15), axis.text.x = element_text(size = 15), axis.title.y = element_text(size = 15), axis.text.y = element_text(size = 15), title = element_text(size = 18), legend.title = element_text(size = 12), legend.text = element_text(size = 12), legend.key = element_blank(), legend.key.width = unit(0.3, 'cm'), legend.key.size = unit(0.1, 'cm'), plot.title = element_text(size = 13, face = "bold"), strip.text = element_text(face = "bold", size = 10))
```

## Does log transforming the response variable improve the fit?

```{r}




```

## Regression model fit

For plotting the model parameters, I will also want to compute confidence intervals around my estimate of the mean. To do this for the linear models and the multilevel models, I follow a tutorial by Solomon Kurz (https://solomonkurz.netlify.app/blog/2021-12-16-use-emmeans-to-include-95-cis-around-your-lme4-based-fitted-lines/). This is a really good tutorial and involves using the *emmean()* function from the emmeans package.

Within the *emmeans()* function, I specify failure criticality _(ttlc.failure)_ for the specs and in my list, I calculate predictions for failure criticalities between 1 s and 3 s. This is outside the range of failures used within the experiment, but because the data appear linear, we can extend out predictions to predict what ttlc.takeover values would be predicted for failures of 3 s.  


```{r}
# Computing 95% CIs using emmeans() function for linear regression model
linear_regression_emmeans <- emmeans(object = mod_1, specs = ~ TLC_failure, at = list(TLC_failure = seq(1.5, to = 10.5, by = .1))) %>% 
  data.frame()

# plotting linear regression model over data
linear_regression_plot <- ggplot() +
  geom_point(data_RTs_cens_NA_removed, mapping = aes(x = TLC_failure, TLC_takeover), position = position_jitter(seed = 42, width = 0.4), alpha = 0.2, size = 1.5) +
  geom_ribbon(data = linear_regression_emmeans, mapping = aes(x = TLC_failure, y = emmean, ymin = lower.CL, ymax = upper.CL), alpha = .5) +
  geom_line(linear_regression_emmeans, mapping = aes(x = TLC_failure, y = emmean), linetype = "dashed", col = "red") +
  geom_point(data_RTs_cens_NA_removed %>%
               dplyr::group_by(TLC_failure) %>%
               dplyr::summarise(mean_takeover = mean(TLC_takeover)), mapping = aes(x = TLC_failure, y = mean_takeover), fill = "white", pch = 21, size = 1.5) + 
  ggtitle("A") +
  xlab(expression(TLC[F] ~ "(s)")) +
  ylab(expression(TLC[T] ~ "(s)")) +
  ylim(0, 7) +
  xlim(0, 11) +
  theme_bw() +
  theme(legend.position = c(.9, .7), axis.title.x = element_text(size = 15), axis.text.x = element_text(size = 15), axis.title.y = element_text(size = 15), axis.text.y = element_text(size = 15), title = element_text(size = 18), legend.title = element_text(size = 12), legend.text = element_text(size = 12), legend.key = element_blank(), legend.key.width = unit(0.3, 'cm'), legend.key.size = unit(0.1, 'cm'), plot.title = element_text(size = 22, face = "bold"), strip.text = element_text(face = "bold", size = 10))

# number of observations per participant
data_RTs_cens_NA_removed %>%
  dplyr::group_by(ppid) %>%
  dplyr::summarise(obs = n()) %>%
  View()
```

## Non-independence 

The data points are not independent individual each because each participants has multiple observations within a condition. Data points belonging to one individual a more closely related to their other data points in comparison to someone else's data points. To highlight this, we select the first 5 participants in different colours. Participant 

```{r}
# example of 5 participants
subset_sample_plot <- ggplot() +
  geom_point(data_RTs_cens_NA_removed %>%
         dplyr::filter(ppid <= 5), mapping = aes(x = TLC_failure, TLC_takeover, col = as.factor(ppid)), position = position_jitter(seed = 42, width = 0.3), alpha = .8, size = 1.5) +
  xlab(expression(TLC[F] ~ "(s)")) +
  ylab(expression(TLC[T] ~ "(s)")) +
  scale_color_discrete(name = "Participant") +
  ggtitle("B") +
  ylim(0, 7) +
  xlim(0, 11) +
  theme_bw() +
  theme(legend.position = "none", legend.key.width = unit(0.1, 'cm'), legend.key.height = unit(0.1, 'cm'), legend.key = element_blank(), axis.title.x = element_text(size = 15), axis.text.x = element_text(size = 15), axis.title.y = element_text(size = 15), axis.text.y = element_text(size = 15), title = element_text(size = 25), legend.title = element_text(size = 12), legend.text = element_text(size = 12), legend.key.size = unit(0.1, 'cm'), plot.title = element_text(size = 22, face = "bold"), strip.text = element_text(face = "bold", size = 10))



# how many observations per participant
data_RTs_cens_NA_removed %>%
  dplyr::filter(ppid <= 5) %>%
  dplyr::group_by(ppid) %>%
  dplyr::summarise(obs = n()) %>%
  View()

# how many participants
data_RTs_cens_NA_removed %>%
  dplyr::filter(ppid <= 5) %>%
  View()
```

## Figure 1

Left panel contains all data the parameters of the model predicting sample means in each condition. Right panel contains an example of 5 participants to illustrate the violation of independence amongst the data points

```{r}
fig_1 <- linear_regression_plot | subset_sample_plot

ggsave(here::here("multilevel_model_HF_applications/plots/fig_1.tiff"), plot = fig_1, width = 16, height = 8, units = 'cm', dpi = 300, type = 'cairo')
```

## Fitting a varying intercept model

Here we fit a varying intercept model. The *(1 | ppid)* part of the model equations fits an intercept for each participant. This accounts for the non-independence of observations by constraining the non-independent clusters to the same intercept. Remember, this is something we need to do as each member of the random effects group has multiple observations. 

```{r}
# fitting a varying intercept model
mod_2 <- lme4::lmer(TLC_takeover ~ TLC_failure + (1 | ppid), data = data_RTs_cens_NA_removed)

# summarizing the model
summary(mod_2)

# generating confidence intervals
confint(mod_2)

coef(mod_2)[1]
```

## Figure 2

In a previous plot, it was highlighted how the repeated observations for each participant within each condition violated the non-independence assumption. Now each participant had been modeled with an intercept, we can update that plot and assign each participant with their own intercept. You'll notice that there are only 4 regression lines. This is because participant 1 and 2 have very similar intercept values, and because have modelled everyone as having a fixed TLC_failure slope, this is exactly the same for everyone. 

This might seem strange given that the scatter plot seems to show that the two participants respond differently as failure get less severe. This is one indication that random slopes might be necessary. 

```{r}
# Computing 95% CIs using emmeans() function for linear regression model
varying_intercept_emmeans <- emmeans(object = mod_2, specs = ~ TLC_failure, at = list(TLC_failure = seq(1.5, to = 10.5, by = .1))) %>% 
  data.frame()

# model predictions - predictions for TLC_t for failure severities between 1.5 s and 10.5 for 5 participants in the model
TLC_failure <- data.frame(TLC_failure = seq(1.5, to = 10.5, by = .1))
ppid <- data.frame(ppid = seq(1, to = 5, by = 1))
pred_list <- expand_grid(ppid, TLC_failure)

# 5 participants we are focusing on
example_5_participants <- data_RTs_cens_NA_removed %>%
  dplyr::filter(ppid <= 5)

mod_2_predict_ppids <- predict(mod_2, newdata = pred_list) %>% 
  data.frame() %>% 
  set_names("y_hat") %>% 
  bind_cols(pred_list)

# example of 5 participants with their specifc intercepts
fig_2 <- ggplot() +
  geom_point(data_RTs_cens_NA_removed %>%
         dplyr::filter(ppid <= 5), mapping = aes(x = TLC_failure, TLC_takeover, col = as.factor(ppid)), position = position_jitter(seed = 42, width = 0.3), alpha = .8, size = 1.5) +
  geom_line(mod_2_predict_ppids %>%
              dplyr::filter(ppid <= 5), mapping = aes(x = TLC_failure, y_hat, col = as.factor(ppid))) +
  xlab(expression(TLC[F] ~ "(s)")) +
  ylab(expression(TLC[T] ~ "(s)")) +
  scale_color_discrete(name = "Participant") +
  ylim(0, 7) +
  xlim(0, 11) +
  theme_bw() +
  theme(legend.position = "none", legend.key.width = unit(0.1, 'cm'), legend.key.height = unit(0.1, 'cm'), legend.key = element_blank(), axis.title.x = element_text(size = 15), axis.text.x = element_text(size = 15), axis.title.y = element_text(size = 15), axis.text.y = element_text(size = 15), title = element_text(size = 25), legend.title = element_text(size = 12), legend.text = element_text(size = 12), legend.key.size = unit(0.1, 'cm'), plot.title = element_text(size = 22, face = "bold"), strip.text = element_text(face = "bold", size = 10))

ggsave(here::here("multilevel_model_HF_applications/plots/fig_2.tiff"), plot = fig_2, width = 8, height = 8, units = 'cm', dpi = 300, type = 'cairo')
```

It's easier to judge the fit if we facet the plot by participant. Whilst fixed slopes seem fine for participant 2 and 3, the fit for participant 1 and 5 might not be optimal. For participant 5, their safety margin appears to be larger when the failure is less severe. This su

```{r}
# faceting the individual regression lines by participant
ggplot() +
  geom_point(data_RTs_cens_NA_removed %>%
         dplyr::filter(ppid <= 5), mapping = aes(x = TLC_failure, TLC_takeover, col = as.factor(ppid)), position = position_jitter(seed = 42, width = 0.3), alpha = .8, size = 1.5) +
  geom_line(mod_2_predict_ppids %>%
              dplyr::filter(ppid <= 5), mapping = aes(x = TLC_failure, y_hat, col = as.factor(ppid))) +
  xlab(expression(TLC[F] ~ "(s)")) +
  ylab(expression(TLC[T] ~ "(s)")) +
  scale_color_discrete(name = "Participant") +
  facet_wrap(~ ppid) +
  ylim(0, 7) +
  xlim(0, 11) +
  theme_plot +
  theme(legend.position = "none", legend.key.width = unit(0.1, 'cm'), legend.key.height = unit(0.1, 'cm'), legend.key = element_blank())
```

## Marginal and conditional effects 

When reading about multilevel models, you will undoubtedly come across "marginal" and "conditional" effects. The terminology can be very confusing (Heiss, 2021), and there are multiple resources on the differences:

https://www.andrewheiss.com/blog/2022/11/29/conditional-marginal-marginaleffects/#conditional-effects-or-effect-of-a-variable-in-an-average-cluster

https://www.andrewheiss.com/blog/2021/11/10/ame-bayes-re-guide/#continuous-effect

https://rpsychologist.com/GLMM-part1-lognormal#simulation-code

To summarise what has been highlighted previously, marginal and conditional effect can be defined as follows:

*Conditional effect*: refers to the average driver i.e, the effect that failure severity has on the average driver. 

*Marginal effect*: the average effect failure severity across all drivers. 

These effects might sound similar but they are subtlety different. In context of the silent failures experiment, a conditional effect refers to the average driver i.e., the fixed effects when the random effects are all set to 0. Hence in our model, this predicts the effect of failure severity on takeover performance for a typical driver. Conversely, a marginal effect refers to the drivers on average. If we simulated 500 new drivers, and took their average on the the response scale, this would represent the population average. 

Luckily, for a linear multilevel model, these conditional effects and marginal effects are equivalent (Magnusson, 2018). 

However if there is a non-linear transformation (i.e, the response variable is log transformed or is approximated by a log normal distribution) then the driver specific and the average driver might not match up. 

It can be demonstrated below that the  the two match up for the current model below. The grand intercept models the fasted response for the typical driver. However if we take the average of the random intercepts, we get identical values. 

```{r}
# grand intercept
fixef(tlc_takeover_varying_intercept)[1]

# average of the random participant intercepts
coef(tlc_takeover_varying_intercept)[1] %>%
  as.data.frame() %>%
  dplyr::summarise(m = mean(ppid..Intercept.))
```

## What actually are random effects?

The *ranef()* function, despite the name, does not extract the random effects per se. Instead, it extracts the conditional models of each participant. These can effectively be thought of as deflections from the grand mean - for a varying intercept model, this is the grand intercept. By adding the conditional modes to the grand intercept, we get the individual participant intercepts. 

```{r}
ranef(mod_2) %>%
  as.data.frame() %>%
  dplyr::mutate(participant_specific_intercept = condval + fixef(mod_2)[1]) %>%
  View()
```

## Figure 3

To understand what conditional modes are, the following section uses them in two ways. Firstly, they are plotted about zero. This highlights that when fitting the model, the conditional modes are estimated via zero-centred Gaussian distribution. This reason for a Gaussian distribution is unknown to me, how I have some ideas. One might simply be computational ease. Another might be that if we want to estimate population level variance of some response, then a normal distribution might be a strong assumption to make. Another is that a Gaussian has relatively thin tales. This means that if individual estimates do not have much data, they shrink towards the average (the tails of the distribution constrain outlying values). This is known as *shrinkage*. Now, I am sure that there are other distributions that also have thin tails, but I think the combination of these factors result in a Gaussian distribution being the default. 

Back to the figures - panel A plots the conditional modes around zero. Panel B plots the predicted intercepts (individual conditional modes + grand intercept) around the grand intercept. 

These two ways of understanding random effects are why some people specify the model equations as being centred on the grand parameter, or being zero centred.  

```{r}
# extracting conditional models
cond_mode <- as.data.frame(ranef(mod_2, condVar = TRUE))

# standard error of the intercepts
cond_mode_SE <- transform(cond_mode,
                          lwr = condval - 1.96 * condsd,
                          upr = condval + 1.96 * condsd)

beta_0_j <- cond_mode_SE$condval # conditional modes
beta_0_j_sd <- cond_mode_SE$condsd # 

# distribution of conditional modes about 0
fig_3_conditional_modes <- ggplot() + 
  geom_point(cond_mode_SE, mapping = aes(x = condval, y = grp)) +
   geom_errorbarh(cond_mode_SE %>%
                   dplyr::arrange(as.integer(as.character(grp))), mapping = aes(x = condval, y = grp, xmin = lwr, xmax = upr), height = .2) +
  geom_vline(mapping = aes(xintercept = 0)) +
  xlab("Conditional modes") +
  ylab("Participant") +
  ggtitle("A") +
  scale_x_continuous(limits = c(-.6, 1), breaks = c(-.5, 0, .5, 1)) +
  theme_bw() +
  theme(legend.position = "none", legend.key.width = unit(0.1, 'cm'), legend.key.height = unit(0.1, 'cm'), legend.key = element_blank(), axis.title.x = element_text(size = 15), axis.text.x = element_text(size = 15), axis.title.y = element_text(size = 15), axis.text.y = element_text(size = 15), title = element_text(size = 25), legend.title = element_text(size = 12), legend.text = element_text(size = 12), legend.key.size = unit(0.1, 'cm'), plot.title = element_text(size = 22, face = "bold"), strip.text = element_text(face = "bold", size = 10))


beta_0 <- summary(mod_2)$coefficients[1,1] # grand intercept
beta_0_SE <- summary(mod_2)$coefficients[1,2] # standard error of grand intercept


b0u0 <- beta_0 + beta_0_j
b0u0SD <- sqrt(beta_0_SE^2 +beta_0_j_sd^2)

b0u0lower <- b0u0 - 2 * b0u0SD
b0u0upper <- b0u0 + 2 * b0u0SD

# creating data frame with participant specific intercepts alongside upper and lower bounds
by_ppid_intercept <- data.frame(b = b0u0,lower = b0u0lower,upper = b0u0upper)
by_ppid_intercept$ppid <- factor(1:12)

by_ppid_intercept <- by_ppid_intercept[order(by_ppid_intercept$b),]

by_ppid_intercept$ppid <- factor(by_ppid_intercept$ppid,levels = as.numeric(by_ppid_intercept$ppid))


fig_3_intercepts <- ggplot() +
  geom_point(by_ppid_intercept %>%
               dplyr::arrange(as.integer(as.character(ppid))), mapping = aes(x = b, y = ppid)) +
  geom_errorbarh(by_ppid_intercept %>%
                   dplyr::arrange(as.integer(as.character(ppid))), mapping = aes(x = b, y = ppid, xmin = lower, xmax = upper), height = .2) +
  geom_vline(mapping = aes(xintercept = fixef(mod_2)[1])) +
  xlab(expression("Predicted" ~ beta[0])) +
  ylab("Participant") +
  ggtitle("B") +
  scale_x_continuous(limits = c(-.6, 1.5), breaks = c(-.5, 0, .5, 1, 1.5)) +
  theme_bw() +
  theme(legend.position = "none", legend.key.width = unit(0.1, 'cm'), legend.key.height = unit(0.1, 'cm'), legend.key = element_blank(), axis.title.x = element_text(size = 15), axis.text.x = element_text(size = 15), axis.title.y = element_text(size = 15), axis.text.y = element_text(size = 15), title = element_text(size = 25), legend.title = element_text(size = 12), legend.text = element_text(size = 12), legend.key.size = unit(0.1, 'cm'), plot.title = element_text(size = 22, face = "bold"), strip.text = element_text(face = "bold", size = 10))

fig_3 <- fig_3_conditional_modes | fig_3_intercepts

ggsave(here::here("multilevel_model_HF_applications/plots/fig_3.tiff"), plot = fig_3, width = 16, height = 9, units = 'cm', dpi = 300, type = 'cairo')
```

## Random effect parameters specify the sampling distribution, not the sample

A key thing to remember is that the standard deviation for the random intercepts in the varying intercept model relates to the sampling distribution from which the intercepts were drawn, rather than the sample of random effects themselves. We can test this by calculating the standard deviation of the random effects, and comparing this to the model estimate. The standard deviation of the sample estimates is .3169, whereas the model estimate for the random participant intercept is .3305. 

These values are similar, as we would expect. However they are not the same because they are measuring different. 

```{r}
# standard deviation of the sample estimates 
ranef(mod_2) %>%
  as.data.frame() %>%
  dplyr::summarise(sample_sd = sd(condval))

# model estimate for the random intercepts
VarCorr(mod_2)
```

## Fitting a varying intercept, varying slope model

Here we fit a varying intercept, varying slope model. The *(TLC_failure | ppid)* part of the model equations fits an intercept for each participant, and allows each participants slope to vary. This accounts for the non-independence of observations by constraining the non-independent clusters to the same intercept, and models the differences in sensitivity between different people in the sample. 

```{r}
# fitting a varying intercept. varying slope model
mod_3 <- lme4::lmer(TLC_takeover ~ TLC_failure + (TLC_failure | ppid), data = data_RTs_cens_NA_removed)

# summarizing the model
summary(mod_3)

# generating confidence intervals
confint(mod_3)

coef(mod_3)[1]
```

## Figure 4

Now a varying intercept varying slope has been fitted, we can see how this fits the data point. Here I plot for 5 example participants. 

```{r}
# Computing 95% CIs using emmeans() function for linear regression model
varying_intercept_slope_emmeans <- emmeans(object = mod_3, specs = ~ TLC_failure, at = list(TLC_failure = seq(1.5, to = 10.5, by = .1))) %>% 
  data.frame()

# model predictions - predictions for TLC_t for failure severities between 1.5 s and 10.5 for 5 participants in the model
TLC_failure <- data.frame(TLC_failure = seq(1.5, to = 10.5, by = .1))
ppid <- data.frame(ppid = seq(1, to = 5, by = 1))
pred_list <- expand_grid(ppid, TLC_failure)

# 5 participants we are focusing on
example_5_participants <- data_RTs_cens_NA_removed %>%
  dplyr::filter(ppid <= 5)

mod_3_predict_ppids <- predict(mod_3, newdata = pred_list) %>% 
  data.frame() %>% 
  set_names("y_hat") %>% 
  bind_cols(pred_list)

# example of 5 participants with their specifc intercepts
fig_4 <- ggplot() +
  geom_point(data_RTs_cens_NA_removed %>%
         dplyr::filter(ppid <= 5), mapping = aes(x = TLC_failure, TLC_takeover, col = as.factor(ppid)), position = position_jitter(seed = 42, width = 0.3), alpha = .8, size = 1.5) +
  geom_line(mod_3_predict_ppids %>%
              dplyr::filter(ppid <= 5), mapping = aes(x = TLC_failure, y_hat, col = as.factor(ppid))) +
  xlab(expression(TLC[F] ~ "(s)")) +
  ylab(expression(TLC[T] ~ "(s)")) +
  scale_color_discrete(name = "Participant") +
  ylim(0, 7) +
  xlim(0, 11) +
  theme_bw() +
  theme(legend.position = "none", legend.key.width = unit(0.1, 'cm'), legend.key.height = unit(0.1, 'cm'), legend.key = element_blank(), axis.title.x = element_text(size = 15), axis.text.x = element_text(size = 15), axis.title.y = element_text(size = 15), axis.text.y = element_text(size = 15), title = element_text(size = 25), legend.title = element_text(size = 12), legend.text = element_text(size = 12), legend.key.size = unit(0.1, 'cm'), plot.title = element_text(size = 22, face = "bold"), strip.text = element_text(face = "bold", size = 10))

ggsave(here::here("multilevel_model_HF_applications/plots/fig_4.tiff"), plot = fig_4, width = 8, height = 8, units = 'cm', dpi = 300, type = 'cairo')
```

## Figure 5

When fitting a multilevel model with varying intercepts and varying slopes, a correlation parameter between the two is also estimated. The following section plots that correlation. 

```{r}
mod_3_ranef <- as.data.frame(coef(mod_3)$ppid) %>%
  dplyr::rename_all(~c("Intercepts", "TLC_failure"))

# correlations between random slopes and random intercepts
fig_5 <- ggplot(mod_3_ranef, mapping = aes(x = Intercepts, y = TLC_failure)) +
  geom_point() +
  xlim(.25, .65) +
  xlab(expression(beta[0][j])) +
  ylab(expression(beta[F][j])) +
  theme_bw() +
  theme(legend.position = "none", legend.key.width = unit(0.1, 'cm'), legend.key.height = unit(0.1, 'cm'), legend.key = element_blank(), axis.title.x = element_text(size = 15), axis.text.x = element_text(size = 15), axis.title.y = element_text(size = 15), axis.text.y = element_text(size = 15), title = element_text(size = 25), legend.title = element_text(size = 12), legend.text = element_text(size = 12), legend.key.size = unit(0.1, 'cm'), plot.title = element_text(size = 22, face = "bold"), strip.text = element_text(face = "bold", size = 10))

ggsave(here::here("multilevel_model_HF_applications/plots/fig_5.tiff"), plot = fig_5, width = 8, height = 8, units = 'cm', dpi = 300, type = 'cairo')
```

### Study 2: Goodridge, C. M., Gonçalves, R. C., Arabian, A., Horrobin, A., Solernou, A., Lee, Y. T., ... & Merat, N. (2023). Gaze Entropy Metrics for Mental Workload Estimation are Heterogenous During Hands-Off Level 2 Automation.

## Load data 

In the original manuscript, participants 34, 39, and 47 were removed. I do the same here, alongside checking the distribution of the data

```{r}
# load data
goodridge_2023_dat <- fread(file = here::here("gaze_entropy_heterogenous/data/entropy.total.csv"))

# removing participants 
goodridge_2023_dat <- goodridge_2023_dat %>%
  tidyr::drop_na() %>%
  dplyr::filter(ppid != 34, ppid != 39, ppid != 47)

# plotting distribution
ggplot(data = goodridge_2023_dat, mapping = aes(x = e.norm)) +
  geom_histogram(aes(fill = as.factor(n_back)), alpha=0.5, bins=50, col = "black") +
  facet_wrap(~ lead)

# 38 participants 
goodridge_2023_dat %>%
  dplyr::group_by(ppid) %>%
  dplyr::slice(1) %>%
  View()
```

## Model fitting

```{r}
mod_4 <- lmer(e.norm ~ n_back * lead + (n_back | ppid), data = goodridge_2023_dat)

summary(mod_4)

confint(mod_4)
```

## Heterogenity intervals

```{r}
# extracting SD of random slopes
random_effects <- VarCorr(mod_4) %>%
    as.data.frame()

sigma_beta_n <- random_effects$sdcor[2]

# relative size of the SD versus the fixed effect
sigma_beta_n / fixef(mod_4)[2]

# upper bound
(fixef(mod_4)[2] + 1.96 * sigma_beta_n)

# lower bound
(fixef(mod_4)[2] - 1.96 * sigma_beta_n)
```

## Figure 6 

This is a strip plot that highlights the individual estimates of the sample, the 95% confidence intervals, and the 95% heterogenity intervals. 

```{r}



```



## Maximal models

```{r}
mod_5 <- lmer(e.norm ~ n_back * lead + (n_back * lead | ppid), data = goodridge_2023_dat)

summary(mod_5)
```


